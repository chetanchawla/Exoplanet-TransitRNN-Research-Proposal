% What will be the final product of this work? (thesis, publication, a new research tool, etc.)

%What do you want to find out? What donâ€™t we already know? 

%Why are you doing this research? Why should we care? (Often, this is a new intriguing result that raises a new question to be investigated. Tie it back to society, the real world.)

%What are the broader impacts of this research to the field, society?


A huge amount of data is produced by Telescopes such as \textbf{Kepler} Space Telescope and \textbf{TESS} (Transiting Exoplanet Survey Satellite), and even wider amounts of data is expected to be produced by upcoming missions like \textbf{PLATO} (PLAnetary Transits and Oscillations of stars) mission by ESA and \textbf{ARIEL} (Atmospheric Remote-sensing Infrared Exoplanet Large-survey). With this volume and diversity of transit data being recorded, there is a strong need for methods which can systematically detect and vet transiting exoplanets, separate them from Astrophysical False Positives and other stellar phenomena (such as stellar flares), and reduces the human intervention in doing so. This, if combined with speed, will result in a pipeline that can automatically find out the Objects of Interest in these missions, classify the transiting phenomena as an exoplanet, other Astrophysical False Positives, such as caused by Eclipsing binaries or variations of stellar flux due to stellar flares, and further help us in parameterization of the detected exoplanets' Radius and Periods.\\

Kepler pipeline employs Vetting systems such as \textbf{Robovetter}, which uses Decision Tress to replicate the manual process of separating a detected transit into a Planet Candidate (PC), Astrophysical Fasle Positive (AFP), Non-Transiting Phenomena (NTP) or an Unknown phenomena (UNK) class, and \textbf{Autovetter}, which is a Machine Learning system using Random Forest based classification to vet the detected transits in the above mentioned classes. However, in Robovetter, heuristics are explicitly defined by humans, while Autovetter is dependent on the features derived by the Kepler's pipeline. The more recent machine learning models also make the use of Deep Learning, a subset of Machine Learning which uses mathematical sub-units called Neurons connected over several computational layers to learn the heuristics from data automatically. \textbf{Astronet} uses a disjoint 1-Dimensional Convolutional Neural Network (CNN) to classify transit signals as exoplanet candidates or non-exoplanet candidates, while \textbf{Exonet} builds on Astronet by adding Scientific Domain Knowledge to improve the classification results. The 1-D CNN incorporates spatial proximities of the data points, which yields better results than the simpler Multi-layered Perceptrons as they learn the local features throughout the time-series, thus making these the state-of-the-art deep learning models for vetting exoplanetary transits.\\

We propose the use of Recurrent Neural Networks in conjecture with 1D-CNNs, which are yet another class of Neural Networks using its output as the input to the network, along with scientific domain knowledge for detection of transit signals in the light curves (which are Stellar flux time series), classification of Exoplanet candidates and Astrophysical False Positives from the Threshold Crossing Events (TCEs), and further parameterization of the detected exoplanets. RNNs are looped, which allows them to retain information throughout the time-series input and use the dependence of sequencing in data points. This means that RNNs can learn heuristics from the global light curve effectively, thereby giving a physical advantage over the models that had been used for studying the transit data previously. It will also be a comparative study between the CNNs and RNNs, the latter of which demonstrates their effectiveness over time-series analysis. The comparative study aims to improve the model architecture for vetting of transits and ultimately leading to a more autonomous pipeline which can optimally sort out events as Threshold Crossing Events, use these TCEs to classify the transiting events into planet transit events with a higher accuracy \& less manual effort and do a preliminary parameterization of transiting exoplanets, which can later be confirmed by Bayesian Fitting and Monte Carlo Markov Chains. We also want to further classify the AFPs intro Eclipsing Binaries (EBs), Background Eclising Binaries (BEBs), Stellar Flares, NTPs and UNK.\\

The research plays out a very important role in finding extra-solar planets (Exoplanets) which could potentially be harbouring intelligent life. With newer telescopes for transit detection, we have more data and need a scalable methodology which can learn how to narrow down the search and the manual effort. Deep Learning is one solution which excels at automatically learning heuristics from data, and RNNs ever more in time-series. Hence, we want to explore the possibility of using them for the classification of potential exoplanet candidates.