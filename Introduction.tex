% What will be the final product of this work? (thesis, publication, a new research tool, etc.)

%What do you want to find out? What donâ€™t we already know? 

%Why are you doing this research? Why should we care? (Often, this is a new intriguing result that raises a new question to be investigated. Tie it back to society, the real world.)

%What are the broader impacts of this research to the field, society?


A huge amount of data is produced by space based Telescopes, such as, Kepler Space Telescope and TESS (Transiting Exoplanet Survey Satellite), and even wider amounts of data is expected to be produced by upcoming missions like ESA's PLATO (PLAnetary Transits and Oscillations of stars) and the ARIEL (Atmospheric Remote-sensing Infrared Exoplanet Large-survey). These transit telescopes aim to find extra-solar planets (exoplanets) which could potentially harbour intelligent life. With the volume and diversity of transit data being recorded, there is a strong need for methods that can systematically detect and vet transiting exoplanets, separate them from Astrophysical False Positives, help in parameterization of the detected planets such as it's radius and reduce the human intervention in doing so.\\

Kepler pipeline employs vetting systems, such as Decision Tree based Robovetter \cite{robovetter} and Machine Learning (Random Forest) based Autovetter \cite{autovetter} to classify the transit events as Planet Candidate (PC), Astrophysical False Positive (AFP) or Non Transiting Phenomenon (NTP). However, in these methods, heuristics are explicitly defined by humans. The more recent methods explore the use of Deep Learning, a subset of Machine Learning which uses sub-units called Neurons connected over several computational layers to learn the heuristics from data automatically, for vetting exoplanetary transits. Some examples of these are Astronet \cite{astronet}, which uses a disjoint 1-Dimensional Convolutional Neural Network (CNN), and Exonet \cite{exonet}, which improves on Astronet by factoring in scientific domain knowledge. The 1-D CNN incorporates spatial proximity of data points, making it appropriate for time-series analysis and the current state-of-the-art deep learning model for vetting.\\

We propose the use of Recurrent Neural Networks, which are a class of networks that loops back their output, with 1D-CNNs and scientific domain knowledge for classification of transit signals as planet or non planet candidates. Additionally, we look at the prospect of RNNs for detection of transit signals in the stellar flux time-series(light curves), classification of AFP nature to Eclipsing Binaries (EBs), star spots, etc. and parameterization of the planet candidates. The motivation behind the use of RNNs is due to their capability to retain information and use these temporal relations for predictions. The project aims to improve the model architecture for vetting of transits and put forward a step to a more autonomous pipeline which can optimally filter in Threshold Crossing Events (TCEs), classify the them with a higher accuracy and do a preliminary parameterization of the exoplanets.\\